# ğŸ“š RAG Chatbot with Streaming Responses

This project is part of the **Junior AI Engineer Assignment** for **Amlgo Labs**.  
The goal is to build a **Retrieval-Augmented Generation (RAG) chatbot** that answers user queries based on a provided document.  
It supports **real-time streaming responses** via a **Streamlit interface**.

---

## ğŸš€ Features
- Document preprocessing and chunking (100â€“300 words).
- Embedding generation using **SentenceTransformers** (`all-MiniLM-L6-v2`).
- Vector database storage with **FAISS**.
- RAG pipeline (Retriever + Generator).
- Streaming responses (token-by-token like ChatGPT).
- **Streamlit UI** with:
  - Input box for natural queries.
  - Streaming answer display.
  - Sources shown under each answer.
  - Reset/clear chat option.

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**
- **Transformers** (HuggingFace)
- **SentenceTransformers**
- **FAISS**
- **Streamlit**
- **PyTorch**

---

## ğŸ“‚ Project Structure
rag_chatbot/
â”‚â”€â”€ data/
â”‚ â””â”€â”€ input.txt # document used for retrieval
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py # document loader + chunker
â”‚ â”œâ”€â”€ embedding.py # embedding + vector DB
â”‚ â””â”€â”€ generator.py # LLM + streaming
â”‚â”€â”€ app.py # Streamlit chatbot app
â”‚â”€â”€ requirements.txt # dependencies
â”‚â”€â”€ README.md



---

## âš™ï¸ Setup & Installation (Windows)
1. Clone the repo:
   ```powershell
   git clone https://github.com/your-username/rag_chatbot.git
   cd rag_chatbot


2. Create virtual environment:
python -m venv rag_env
rag_env\Scripts\activate

3. Install dependencies:
pip install -r requirements.txt

4. Deployment Link:
https://ragchatbot-manas.streamlit.app/

4. Add your document:
Place it in data/input.txt

5. Run the Chatbot
streamlit run app.py
